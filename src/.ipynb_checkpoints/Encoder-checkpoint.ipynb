{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17d1f24-038f-4225-9237-b5f30f1d5a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Shakespeare's work is built from a set of cardinality:  65 \n",
      "\n",
      "output integer representation of a given sequence of chars\n",
      "[58, 43, 57, 58, 47, 52, 45, 1, 43, 52, 41, 53, 42, 43, 56]\n",
      "testing encoder\n",
      "torch.Size([1115394]) <built-in method type of Tensor object at 0x000001DEFBD35B20>\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56])\n"
     ]
    }
   ],
   "source": [
    "# So we need to tokenize the characters in the data set. Let's begin by parsing the data set \n",
    "# and constructing a set of characters which comprise the data set.\n",
    "\n",
    "alphabet = \"\"\n",
    "with open('datasets/tinyshakespeare.txt', 'r') as file:\n",
    "    text = alphabet = file.read()\n",
    "    print(len(alphabet))\n",
    "#print(alphabet)\n",
    "\n",
    "# Construct the set\n",
    "alphabet = sorted(list(set(alphabet)))\n",
    "print(''.join(alphabet))\n",
    "print(\"Shakespeare's work is built from a set of cardinality: \", len(alphabet), \"\\n\")\n",
    "\n",
    "# Create simple encoder. E: A -> Z.\n",
    "# E is a bijective map (our encoder) which maps characters in alphabet set to the set of integers.\n",
    "# This is a character-level tokenizer.\n",
    "encodeMap = { ch:i for i,ch in enumerate(alphabet) }\n",
    "decodeMap = { i:ch for i,ch in enumerate(alphabet) }\n",
    "\n",
    "encode = lambda x: [encodeMap[i] for i in x]\n",
    "decode = lambda x : ''.join([decodeMap[i] for i in x])\n",
    "print(\"output integer representation of a given sequence of chars\")\n",
    "print(encode(\"testing encoder\"))\n",
    "# Test inverse\n",
    "print(decode(encode(\"testing encoder\")))\n",
    "\n",
    "# Next up we will tokenize the tinyshakespeare data set\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "# print first 500 characters\n",
    "print(data[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aaf4e48-13e2-45a4-af1e-30375d09da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56,  ..., 43, 56, 43])\n"
     ]
    }
   ],
   "source": [
    "# split data into train and validation sets\n",
    "# allocate .9 for training .1 for validation\n",
    "n = int(0.9*len(data))\n",
    "train_set = data[:n]\n",
    "validation_set = data[n:]\n",
    "print(train_set)\n",
    "\n",
    "# we use the valid set to test overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b1b955-97ef-4f6b-8e28-5ab0b0dd43d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next step: training the transformer\n",
    "# e train in a chunk by chunk fashion rather than feeding the entire data set\n",
    "# define the max_len of these chunks\n",
    "block_size = 8\n",
    "train_set[:block_size + 1]\n",
    "\n",
    "# Included in a single block is actually 8 samples\n",
    "# For the current block, say # [18, 47, 56, 57, 58,  1, 15, 47, 58].\n",
    "# When we see 18, 47 comes next. When we see 18, 47, 56 comes next, \n",
    "# and so on to a total of 8 in the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb0a1fd-fcbe-4b38-b173-ab796a5f3afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ix 1d tensor\n",
      "torch.Size([4])\n",
      "tensor([ 76049, 234249, 934904, 560986])\n",
      "inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "# Start sampling random sections of the data set to form our chunks which\n",
    "# we feed to the transformer\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many sequences we process in parallel\n",
    "block_size = 8 # maxlen for predictions\n",
    "\n",
    "def construct_batch(set_type):\n",
    "    # generate batch of data inputs x and targets y\n",
    "    data = train_set if set_type == 'train' else validation_set\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print('the ix 1d tensor')\n",
    "    #print(ix.size())\n",
    "    #print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # construct a stack of the 1d tensors\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # target offset by 1 for inputs\n",
    "    return x, y\n",
    "\n",
    "xb, yb = construct_batch('train')\n",
    "print('inputs: ')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets: ')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "# Everytime we run construct_batch() we'll get a new batch for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6898a-e47a-43af-8d57-f716527ba544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the batch of input we are ready to feed it into a neural net.\n",
    "# We will use the Bigram Language Model (BLM)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
